# -*- coding: utf-8 -*-
"""Flowers_Recognition_03_April_PIAIC_91502.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17VLcHPjZmlWWpIPWxJCpildByES5d-PC

Assignment: Flowers Recognition <br>
Dataset Description:<br>

This dataset contains 4242 images of flowers.<br>
The data collection is based on the data flicr, google images, yandex images.<br>
You can use this datastet to recognize plants from the photo.<br>

Attribute Information:<br>
The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>
For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>
<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>
This is a Multiclass Classification Problem.<br>

WORKFLOW : <br>
Load Data <br>
Split into 60 and 40 ratio.<br>
Encode labels.<br>
Create Model<br>
Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>
Train the Model.<br>
If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>
Prediction should be > 85%<br>
Evaluation Step<br>
Prediction<br>

Data : <br>
https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing
"""

import os
import cv2
import pickle
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import models
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import RMSprop



from google.colab import drive
drive.mount('/content/drive')

data_dir = '/content/drive/MyDrive/PIAIC/Flowers'
categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']
data = []

#flower = os.walk('/content/drive/MyDrive/PIAIC/Flowers')

#flower

categories.count

type(categories)

def make_data():
  for category in categories:
    path = os.path.join(data_dir, category)
    label = categories.index(category)

    for img_name in os.listdir(path):
      image_path = os.path.join(path, img_name)
      image = cv2.imread(image_path)

      try: 
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, 224, 224)

        image = np.array(image, dtype=np.float32)

        data.append([image, label])
      except Exception as e: 
        pass
        
print(len(data))
pik = open('data.pickle', 'wb')      
pickle.dump(data, pik)
pik.close()

make_data()

def load_data():
  pick = open('data.pickle', 'rb')
  data = pickle.load(pick)
  pick.close()

  np.random.shuffle(data)

  feature = []
  labels = []

  for img, label in data:
    feature.append(img)
    label.append(label)

  feature = np.array(feature, dtype= np.float32)
  labels = np.array(labels)

  feature = feature/255.0

  return [feature, labels]


from utils load_data()
from sklearn.model_selection import train_test_split

(feature, labels) = load_data()

x_tarin, x_test, y_train, y_test = train_test_split(feature, labels, test_size = 0.4)
categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']

input_layer = tf.keras.layers.input([224,244, 3])
conv1 = tf.keras.layers.Conv2d(filters = 32, kernal_size= (5,5), padding = 'same',  activation=  'relu')(input_layer)
pool1 = tf.keras.layers.MaxPooling2D(pool_size= (2,2))(conv1)

conv2 = tf.keras.layers.Conv2d(filters = 64, kernal_size= (3,3), padding = 'same',  activation=  'relu')(pool1)
pool2 = tf.keras.layers.MaxPooling2D(pool_size= (2,2), strides=(2,2))(conv2)

conv3 = tf.keras.layers.Conv2d(filters = 96, kernal_size= (3,3), padding = 'same',  activation=  'relu')(pool2)
pool3 = tf.keras.layers.MaxPooling2D(pool_size= (2,2), strides= (2,2))(conv3)

conv4 = tf.keras.layers.Conv2d(filters = 96, kernal_size= (3,3), padding = 'same',  activation=  'relu')(pool3)
pool4 = tf.keras.layers.MaxPooling2D(pool_size= (2,2), strides= (2,2))(conv4)

flt1 = tf.keras.layers.Flatten()(pool4)
dn1 = tf.keras.layers.Dense(512, activation= 'relu', )(flt1)

out = tf.keras.layers.Dense(5, activation= 'softmax')(dn1)

model = tf.keras.Model(input_layer, out)

model.compile(optimizer='adam',   loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=100, epoches=10)